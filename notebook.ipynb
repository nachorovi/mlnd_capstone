{
  "cells": [
    {
      "metadata": {
        "_uuid": "815b9b413850530451e01206ddce063f0e7c53c3"
      },
      "cell_type": "markdown",
      "source": "Questions:\n* Is 'roc_auc_score' an appropriate metric? What else could I use? I mreged previous_application with application_train, I got a higher 'roc_auc_score' but a lower submission score.\n* A: \n* When handling categorical features. Do I need to use pd.factorize? see  https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772. I'm just using get_dummies() directly.\n* A: You can use both, you have to what works best for your dataset. But both can work\n\nDONE:\n* For previous_application after I run the simple imputer I don't have any NaN in the np ndarray, but when I turn it into a pandas DataFrame it has 11109336. I need to turn it into a pandas DataFrame to merge it with application_train. What can I do?\n* A: Question is not clear\n* When using simple imputer, I lose the column names. It turns the pd.DataFrame into a np.ndarray. Is this the right process, or are there other ways to handle missing data, NaN, Inf, numbers too big for INT32, etc?\n* A: Consider 'pd.fillna()'. https://pandas.pydata.org/pandas-docs/stable/missing_data.html\n* Should I do one-hot encoding before or after merging the different datasets (ex, application_train & previous_application)?\n* A: Merger, one-hot encoding fitting the model.\n* I get a better competition score by training my model only with application_train.csv than what I get when I train it will ALL the datasets. Am I merging them correctly?\n* A: Now that I do one-hot encoding BEFORE merging I get better results with ALL the data than with app_train alone.\n* Creating Flat Dataset. When I mreged previous_application with application_train using .groupby().mean() it dropped the categorical features! How do I avoid this?\n* A: Do one-hot encoding first."
    },
    {
      "metadata": {
        "_uuid": "a50ca0e6adc3396caaee0109fd82fee783d1073d"
      },
      "cell_type": "markdown",
      "source": "June 7 through June 17\nFuture steps - Must do:\n* Data visualization - See screenshot for variables to go after first: EXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3, DAYS_BIRTH, AMT_ANNUITY, AMT_CREDIT, DAYS_ID_PUBLISH, pcb_CNT_INSTALMENT_FUTURE, DAYS_REGISTRATION, DAYS_EMPLOYED.\n* Add feature importance graph for RFR\n* Clean Notebook.\n* Review Capstone project proposal response.\n* Normalizing data - See screenshot for variables to go after first: EXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3, DAYS_BIRTH, AMT_ANNUITY, AMT_CREDIT, DAYS_ID_PUBLISH, pcb_CNT_INSTALMENT_FUTURE, DAYS_REGISTRATION, DAYS_EMPLOYED.\n* Handling skewed data - See screenshot for variables to go after first: EXT_SOURCE_1, EXT_SOURCE_2, EXT_SOURCE_3, DAYS_BIRTH, AMT_ANNUITY, AMT_CREDIT, DAYS_ID_PUBLISH, pcb_CNT_INSTALMENT_FUTURE, DAYS_REGISTRATION, DAYS_EMPLOYED.\n* When running GridSearchCV then use Train Test Split, but when just training the model don't split the data. Is the competition test higher? Is this what the other kernels do?\n* LGBM - Tune hyperparameters with GridSearchCV\n* Review other kernels:\n  - 0.789, feature engineering, LGBM: https://www.kaggle.com/shep312/lightgbm-harder-better-slower\n  - 0.785, feature engineering, LGBM: https://www.kaggle.com/cklwankaggle/lightgbm-try\n  - 0.782, feature engineering, LGBM: https://www.kaggle.com/gregory711/good-fun-with-ligthgbm\n  - 0.781, feature engineering, LGBM, metric, kfold: https://www.kaggle.com/kosovanolexandr/ligthgbm-0-781-home-credit-default-risk\n  - 0.779, EDA, feature engieering, handling skewed & missing data: https://www.kaggle.com/sukhyun9673/basic-baseline-with-lgb-v3-categocial-not-yet\n  - 0.778, simple, LGBM: https://www.kaggle.com/ashukr/good-fun-with-ligthgbm\n  - 0.777 feat eng, handle missing data?, LGBM, Kfold: https://www.kaggle.com/blackbee2016/good-fun-with-automation\n  - ++ EDA, multiple regressors: https://www.kaggle.com/pavanraj159/loan-repayers-v-s-loan-defaulters-home-credit\n  - +Mem reduction, hyperparameter tunning: https://www.kaggle.com/mlisovyi/lightgbm-hyperparameter-optimisation-lb-0-761\n  - Flatenning dataset, LGBM hyperparameters: https://www.kaggle.com/shep312/lightgbm-with-weighted-averages-dropout-787/code\n  - feature engineering, XGB model: https://www.kaggle.com/shenba/home-credit-eda-23may2018\n  - R, EDA, XGB & LGBM models: https://www.kaggle.com/ambarish/eda-xgb-lgbm-home-credit-default-risk\n  - EDA, LGBM: https://www.kaggle.com/kosovanolexandr/home-credit-default-risk-competition\n  - EDA, no model: https://www.kaggle.com/gpreda/home-credit-default-risk-extensive-eda\n  - -EDA: https://www.kaggle.com/gauravtaneja/home-credit-take0\n* Try other regressors: GBRT, AdaBoost, SGDC\n  - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor\n  - http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n* Try using other metrics to evaluate the model's performance to see if they more accureately align with the project score.\n* Add reference to other kernels in mine:\n  - https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772\n  - https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code\nReport:\n* Preliminary results\n\nJune 18 through July 1\n- Report:\n* MAKE AN ENSEMBLE METHOD OF MULTIPLE MODELS\n  - http://scikit-learn.org/stable/modules/ensemble.html#forest\n* WEEK1: I should have a skeleton of all the areas of the report to share with mentor.\n* WEEK2: I should have a first full version of the report to share with mentor and ready to submit\n\n- Future steps - Nice to do:\n* Only apply one-hot encoding to columns which are not numeric:\n  - https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding\n* Consider doing 'pd.factorize' for one-hot encoding\n* CREATE A scikit-learn Pipeline\n* Measuring model/learner performance using other evaluation metric (LR+, f1, r2)?\n  - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n  - http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix\n* Hyperparameter tunening (different values until I find a max, use higher percentage of training & validation data)\n* Review Handling missing or invalid data, other better methods?\n  - https://www.kaggle.com/dansbecker/handling-missing-values\n* See if sklearn.model_selection.'KFold' could yield a better result than 'train_test_split'\n* Consider other ways to merge data or new features for feature engineering:\n  - https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code\n\nDONE:\n* Review Capstone project report requirements.\n* Re-train LGBM model with same parameters but ALL data. Submit. 0.772. Same as the other kernel https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772\n* Try one-hot encoding on the individual datasets before merging. Create a function. Do fillna after merging. Using the other data files (Feature Engineering, Create flat dataset), categorical features are being dropped.\n* Re-train LGBM model with same parameters but app_train data only. Submit. 0.747.\n* Re-train LGBM model with same parameters but ALL data. Submit. 0.745.\n* Re-train model with same parameters but all data. Submit. 0.719.\n* Handle missing and categorical variables for the Flat (ALL) dataset before splitting the data. Explain why. Submit. 0.732.\n* Remove SK_ID_CURR from dataset before fitting the model\n* Add feature importance - For LGBM & RFR (without graph)\n* Try other regressor: LGBM - First pass complete, performance is much lower than example\n* Using the other data files (Feature Engineering, Create flat dataset) first pass complete\n* Handling missing or invalid data\n* Split train & validation set\n* Hyperparameter tunening\n* Measuring model/learner performance using evaluation metric (auc_roc_score)\n* Handle missing data or NaN, try with pd.fillna()"
    },
    {
      "metadata": {
        "_uuid": "d355f28e4f031ceb02bb7223ae79f96353cff7c8"
      },
      "cell_type": "markdown",
      "source": "    Preliminary results:\n- Categorical values turned into numerical features with one-hot encoding scheme\n- Fill missing or wrong values\n- RFR Default values, only application training data, score: 0.591\n- RFR Best values with GridSearchCV, only application training data, score: 0.722 <- 0.62 (surpassing the 0.688 benchmark for Random Forrest)\n- Got a score of 0.732 with the same model parameters, but by merging train & test datasets before doing pre-processing.\n- RFR Best values with GridSearchCV, ALL available data, score: 0.709 & 0.710\n- I'm still don't why with ALL the datasets I get a lower competition score than with just application_train.\n- I'm still not sure why I keep getting a higher roc_auc_score with ALL the datasets than with just application_train, but the competition score is lower.\n- LGBM Best values with GridSearchCV, ALL available data, score: 0.745\n- LGBM Best values with GridSearchCV, app_train available data, score: 0.745\n- I don't know why the score was so low. Based on the original kernel (https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772) the score should have been 0.772.\n- Lessons learnt so far:\n- Need and how to create a flat datasat from multiple datafiles. Explain what I did. Do some little research. Other ways to merge the data that doesn't use mean.\n- Feature engineering. More art that science. Explain concept. They only new feature I created is the count of number of records when there are multiple number of records of some typer per unique load id SK_ID_CURR. What other features could be created? How? (from the result of the data analysis & experience)\n- Problem when merging datasets. Categorical values were being dropped. when merging. Solution. Do one-hot encoding on each dataset before merging. Retest on RFR, LGBM with app_train only (shouldn't be needed, I already know whit score) with ALL the NEW dataset, it should have several new features from the merged datasets.\n- Merge train and test datasets together to do the pre-processing. Explain. Makes the mean more meaningful when completing empty values with the column mean. And also makes sure the test dataset has the same features than the train set. Otherwise if the test set is smaller there is a chance that it doesn't have all the categorical features, so when you apply one-hot encoding you'll end up missing features and the prediction will fail because the model and the test dataset sizes don't match.\n- ???? Best values with GridSearchCV, ALL available data, score: ? (PENDING)\n- Handling missing data (Why don't they do it?)\n- Handling Categorical variables, why do they use pd.factorize?\n- Explain why I keep dataset merged before separating train and validation set. The mean used is more relevant, given that the test data set with be fewer samples. The reason to do one-hot encoding all together is because both the training and validation dataset need to have the same features, and doing it togethers ensures this.\n- Normalizing Data (PENDING)\n- Unskewing Data (PENDING)\n\nAbbreviations:\nRFR: Random Forest Regressor\n????: Another regressor"
    },
    {
      "metadata": {
        "_uuid": "9615588ff15ee992f488696fa0a5fa1394bb2707"
      },
      "cell_type": "markdown",
      "source": "# **Sections:**\n[1. Import libraries & support functions](#import)  \n[2. Dataset preparation](#data_prep)  \n[3. Exploratory Data Analysis (EDA)](#eda)  \n&nbsp; [3.1 Application Train](#eda_app_train)  \n[4. Feature Engineering](#feat_eng)  \n&nbsp; [4.1 Create a Flat Dataset](#flat_dataset)  \n&nbsp; [4.2 Handle Skewed Continuous Data](#4.1)  \n&nbsp; [4.3 Normalize Continuous Data](#4.2)  \n&nbsp; [4.4 Handle Categorical Variables](#4.3)  \n&nbsp; [4.5 Handle Missing Data](#4.4)  \n&nbsp;&nbsp; [4.5.1 Previous Applications](#4.5)  \n[5. Split Data into Training and Validation](#5)  \n[6. Hyperparameter Tuning](#6)  \n[7. Model Fitting & Prediction](#7)  "
    },
    {
      "metadata": {
        "_uuid": "922c9a490d610b6b4d927a90ff25c15e208ae8ac"
      },
      "cell_type": "markdown",
      "source": "Acknowledgements:\n- Flattening dataset, LGBM model starting point: https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772\n- General ideas: https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code\n- Reducing memory footprint: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage"
    },
    {
      "metadata": {
        "_uuid": "75f2d953491f905a4c3e01991275125d419519bb"
      },
      "cell_type": "markdown",
      "source": "# <a id=\"import\">1 Import Libraries and create support functions</a>"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSVfile I/O (e.g. pd.read_csv)\nimport os\nfrom plotly.offline import init_notebook_mode, iplot\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\nimport seaborn as sns\nfrom plotly import tools\n# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\nfrom sklearn.ensemble import RandomForestRegressor\n# http://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n# https://github.com/Microsoft/LightGBM\nimport lightgbm as lgb\n# Add evaluation metric to measure the model's performance\n# Regression metrics available:\n# http://scikit-learn.org/stable/modules/classes.html#regression-metrics\n# http://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n# http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc\n# http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n# Cannot use sklearn.metrics.accuracy_score as it is a Classification metric\nfrom sklearn.metrics import make_scorer, r2_score, roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom time import time\nfrom IPython.display import display # Allows the use of display() for DataFrames\n# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\nfrom sklearn.model_selection import train_test_split\n\n#warnings.filterwarnings(\"ignore\")\ninit_notebook_mode(connected=True)",
      "execution_count": 1,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ffc696cb463655b657ded7192c08a3ced678eab1"
      },
      "cell_type": "code",
      "source": "# Enable Debugging while I test things\ndebugging = False # True or False",
      "execution_count": 2,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0dc45408902e93d5cc4e3b7825abe8d9d5d5914",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Support functions\ndef bar_hor(df, col, title, color, w=None, h=None, lm=0, limit=100, return_trace=False, rev=False, xlb = False):\n    cnt_srs = df[col].value_counts()\n    yy = cnt_srs.head(limit).index[::-1] \n    xx = cnt_srs.head(limit).values[::-1] \n    if rev:\n        yy = cnt_srs.tail(limit).index[::-1] \n        xx = cnt_srs.tail(limit).values[::-1] \n    if xlb:\n        trace = go.Bar(y=xlb, x=xx, orientation = 'h', marker=dict(color=color))\n    else:\n        trace = go.Bar(y=yy, x=xx, orientation = 'h', marker=dict(color=color))\n    if return_trace:\n        return trace \n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n\ndef bar_hor_noagg(x, y, title, color, w=None, h=None, lm=0, limit=100, rt=False):\n    trace = go.Bar(y=x, x=y, orientation = 'h', marker=dict(color=color))\n    if rt:\n        return trace\n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n\n\ndef bar_ver_noagg(x, y, title, color, w=None, h=None, lm=0, rt = False):\n    trace = go.Bar(y=y, x=x, marker=dict(color=color))\n    if rt:\n        return trace\n    layout = dict(title=title, margin=dict(l=lm), width=w, height=h)\n    data = [trace]\n    fig = go.Figure(data=data, layout=layout)\n    iplot(fig)\n    \ndef gp(col, title):\n    df1 = app_train[app_train[\"TARGET\"] == 1]\n    df0 = app_train[app_train[\"TARGET\"] == 0]\n    a1 = df1[col].value_counts()\n    b1 = df0[col].value_counts()\n    \n    total = dict(app_train[col].value_counts())\n    x0 = a1.index\n    x1 = b1.index\n    \n    y0 = [float(x)*100 / total[x0[i]] for i,x in enumerate(a1.values)]\n    y1 = [float(x)*100 / total[x1[i]] for i,x in enumerate(b1.values)]\n\n    trace1 = go.Bar(x=a1.index, y=y0, name='Target : 1', marker=dict(color=\"#96D38C\"))\n    trace2 = go.Bar(x=b1.index, y=y1, name='Target : 0', marker=dict(color=\"#FEBFB3\"))\n    return trace1, trace2 ",
      "execution_count": 3,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "85a7a3fd4c8cad2c91d88d8df268022bc00c6c30"
      },
      "cell_type": "code",
      "source": "# This implementation was copied from: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df",
      "execution_count": 4,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "953d520a8eb9c6fb820c57ea10ed79a691ecb8c8"
      },
      "cell_type": "markdown",
      "source": "# <a id=\"data_prep\">2 Dataset preparation</a>"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "_kg_hide-input": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# List available data files\n#print(os.listdir(\"../input\"))\nprint(\"Loading data files...\")\n\nstart = time()\n# Load the Point of Sale Cash balance dataset\nposc_bal = reduce_mem_usage(pd.read_csv(\"../input/POS_CASH_balance.csv\"))\n# Load the Bureau Balance dataset\nbureau_bal = reduce_mem_usage(pd.read_csv(\"../input/bureau_balance.csv\"))\n# Load the Application Training dataset\napp_train = reduce_mem_usage(pd.read_csv(\"../input/application_train.csv\"))\n# Load the Previous Applications dataset\nprev_app = reduce_mem_usage(pd.read_csv(\"../input/previous_application.csv\"))\n# Load the Installements Payments dataset\ninst_pay = reduce_mem_usage(pd.read_csv(\"../input/installments_payments.csv\"))\n# Load the Credit Card Balance dataset\ncc_bal = reduce_mem_usage(pd.read_csv(\"../input/credit_card_balance.csv\"))\n# Load the Application Testing dataset\napp_test = reduce_mem_usage(pd.read_csv(\"../input/application_test.csv\"))\n# Load the Bureau dataset\nbureau = reduce_mem_usage(pd.read_csv(\"../input/bureau.csv\"))\nend = time()\n\nprint(\"Finished loading data files and running memory optimization in {} seconds.\".format(int(round(end - start))))",
      "execution_count": 5,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "dbef641ee2d8d5c94a0a5641d4a526b4aa7d4942"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "7bfe6928a00aaceccc2af19ccee97ec86604c55d"
      },
      "cell_type": "markdown",
      "source": "# <a id=\"eda\">3 Exploratory Data Analysis (EDA)</a>"
    },
    {
      "metadata": {
        "_uuid": "582003a957fda9e1e21229825efb56e3d86d9c2f"
      },
      "cell_type": "markdown",
      "source": "## <a id=\"eda_app_train\">3.1 Application Train dataset</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61d33facd34c5856f6f3562228ddd474ba93df5b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "'''\n# Display the first 5 records of application_train.csv\ndisplay(data_train.head())\n# Display the first 5 records of application_test.csv\ndisplay(data_test.head())\n# See the first 5 rows of the dataframe\ndisplay(prev_app.head())\n\n# DataFrame statistics summary for selected columns\ndata_train[[\"AMT_INCOME_TOTAL\", \"AMT_CREDIT\", \"AMT_ANNUITY\", \"AMT_GOODS_PRICE\"]].describe()\n#print(len(data_train.columns))\n'''",
      "execution_count": 5,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b704c1e1fb3c8c911933e64d26155a7fbc8c63d1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "'''\n# Total number of records\nprint(\"Total number of records in the train dataset: {:,}\".format(len(data_train)))\n# Total number of features. Excluding the load ids (SK_ID_CURR) and the target variable (TARGET).\nprint(\"Total number of features in the train dataset: {}\".format(data_train.shape[1] - 2))\n\n# Total number of records\nprint(\"Total number of records in the test dataset: {:,}\".format(len(data_test)))\n# Total number of features. Excluding the load ids (SK_ID_CURR). There is NO target variable (TARGET) in the test dataset.\nprint(\"Total number of features in the test dataset: {}\".format(data_test.shape[1] - 1))\n\n# Total number of features. Excluding the current loan ids (SK_ID_CURR) and the previous loan ids (SK_ID_PREV)\nprint(\"Total number of features of previous applications, before one-hot encoding: {}\".format(prev_app.shape[1] - 2))\nprint(\"Previous applications has {:,} samples\".format(prev_app.shape[0]))\n# Check if therer is any NaN value in the dataset\nprint(\"Total number of NaN in the dataframe: {:,}\".format(prev_app.isnull().sum().sum())) # TODO: REMOVE\n'''",
      "execution_count": 6,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "07cf91e31284eee977d60508585ddb962665bffc"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_target\">3.1.1 Target Label</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10bd1b898552f438389d8bfe962181528d4aa344",
        "_kg_hide-input": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "bar_hor(app_train, \"TARGET\", \"Distribution of Target Variable\" , [\"#44ff54\", '#ff4444'], h=350, w=600, lm=200, xlb = ['Target : 1','Target : 0'])",
      "execution_count": 7,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3fe5a388f860fb1ebdc3698221db4e0c66697726"
      },
      "cell_type": "markdown",
      "source": "COMPLETE - Analysis of Target Variable\nDefinition: Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)"
    },
    {
      "metadata": {
        "_uuid": "4e5d77c69a334ed1e553fb1d98c190491c6eb59d"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_ext_source_1\">3.1.? EXT_SOURCE_1</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f64b90854e1a68da512e4eb3cd3062375d19e08a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#app_train['EXT_SOURCE_1'].isnull().sum()",
      "execution_count": 8,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "85f0b3f29bcbf6c1b9969e110f77659116dcb4f1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train['EXT_SOURCE_1'].isnull().sum()\n# There are many missing values\n# WILL HAVE TO COME BACK TO THIS.\n# BUT GIVEN IT IS ALREADY NORMALIZED, THERE IS NOT MUCH I CAN CHANGE\n#plt.figure(figsize=(12,5))\n#plt.title(\"Distribution of EXT_SOURCE_1\")\n#ax = sns.distplot(app_train[\"EXT_SOURCE_1\"])",
      "execution_count": 9,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "eea21f9b1482de878e8d615db3b66cf0cdccc94d"
      },
      "cell_type": "markdown",
      "source": "Analysis\nNormalized score from external data source"
    },
    {
      "metadata": {
        "_uuid": "f772bd99aa08e352a02b24e9a36bb7fb785438e8"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_ext_source_2\">3.1.? EXT_SOURCE_2</a>"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "collapsed": true,
        "_uuid": "021b68f6931c2efb5a0bff288e6929e80c6c1eaa"
      },
      "cell_type": "code",
      "source": "# grafico",
      "execution_count": 10,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "5122c592cf97c02f830ec80856570a9108491d4b"
      },
      "cell_type": "markdown",
      "source": "Analysis - Tal vez los puedo juntar\nNormalized score from external data source"
    },
    {
      "metadata": {
        "_uuid": "e80dbc071362ee25f5d8ade960272d37cbc23a17"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_ext_source_3\">3.1.? EXT_SOURCE_3</a>"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "collapsed": true,
        "_uuid": "dfde7115f6814120058dc16614b10ee60f734738"
      },
      "cell_type": "code",
      "source": "# Grafico",
      "execution_count": 11,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "c76845bcb2a971a2c9b18e9c640c2dcac46482c4"
      },
      "cell_type": "markdown",
      "source": "Analysis\nNormalized score from external data source"
    },
    {
      "metadata": {
        "_uuid": "58286321323f0429fc005f127da08a3a313e73b4"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_days_birth\">3.1.? DAYS_BIRTH</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40b3860072eade6cf15eb00bd63d4c64f3b8256d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "'''\n# NORMALIZE\nfrom sklearn.preprocessing import MinMaxScaler\napp_train_copy = app_train.copy()\n\nscaler = MinMaxScaler()\n# Full list of top ten features, discounting EXT_SOURCE_X becuase they are already normalizaed:\n# ['DAYS_BIRTH', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYS_ID_PUBLISH', 'pcb_CNT_INSTALMENT_FUTURE', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED']\n\n# numerical = ['DAYS_BIRTH', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYS_ID_PUBLISH']\n# 12 entries in 'AMT_ANNUITY' are NaN - I need to fix that first before Normalizing\n\n# 'pcb_CNT_INSTALMENT_FUTURE' belongs to a different dataset\n\n# numerical = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_ID_PUBLISH']\n\nnumerical = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED']\n\n\napp_train_copy[numerical] = scaler.fit_transform(app_train_copy[numerical])\n\ndisplay(app_train_copy[numerical].head())\n\ndisplay(app_train_copy[numerical].isnull().sum().sum())\n\n\n# SKEWED VALUES:\n#   DAYS_EMPLOYED\n'''",
      "execution_count": 12,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3b9db5c728f1ecc76dbc3034aae55339ef96e471",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of DAYS_BIRTH\")\nax = sns.distplot(app_train[\"DAYS_BIRTH\"])",
      "execution_count": 13,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "cbee9d1351cd7782d10421a8e0451b742e2b3a93"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_amt_annuity\">3.1.? AMT_ANNUITY</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b01f08e63e97400c879e27b79a26a51246220327",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "'''\n# ERROR: ValueError: cannot convert float NaN to integer\n\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of AMT_ANNUITY\")\nax = sns.distplot(app_train[\"AMT_ANNUITY\"])\n\nplt.figure(figsize=(12,5))\nplt.title(\"Distribution of AMT_ANNUITY\")\nax = sns.distplot(app_train_copy[\"AMT_ANNUITY\"])\n'''",
      "execution_count": 14,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "bcfd0ef91ca9808e27da32145c45371beff0c80c"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_amt_credit\">3.1.? AMT_CREDIT</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9c1f7a52f3f0fb9305ca4249cd7d9dcf0368d37",
        "_kg_hide-input": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of AMT_CREDIT\")\nax = sns.distplot(app_train[\"AMT_CREDIT\"])",
      "execution_count": 15,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "8bf53310dfa0495ad95208bfcb2d0c58e009ea29"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "1c752a1fa63fdfc935821070be0d8c2dfca2e65b"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_days_id_publish\">3.1.? DAYS_ID_PUBLISH</a>"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79b55cb1b04b535c2d19624aa5033985b83ae5d1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of DAYS_ID_PUBLISH\")\nax = sns.distplot(app_train[\"DAYS_ID_PUBLISH\"])",
      "execution_count": 16,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "05162a010684cd8479b53b8d79945671bc0ad958"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_days_registration\">3.1.? DAYS_REGISTRATION</a>"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "2c483d1556ed945ca5556e700574fb21b8ee2e04",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of DAYS_REGISTRATION\")\nax = sns.distplot(app_train[\"DAYS_REGISTRATION\"])",
      "execution_count": 17,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "aefa0e29999b40980185954882728281c85e2dca"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_app_train_days_employed\">3.1.? DAYS_EMPLOYED</a>"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "trusted": true,
        "_uuid": "108ad9d9f5eb38cb48af41300482afa7550a95b3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of DAYS_EMPLOYED\")\nax = sns.distplot(app_train[\"DAYS_EMPLOYED\"])",
      "execution_count": 18,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "a834b76dd116a32ecb555affef438c24873502b9"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"eda_posc_bal_cnt_installment_future\">3.?.? CNT_INSTALLMENT_FUTURE</a>"
    },
    {
      "metadata": {
        "_uuid": "6c1405fd3abf934175c5b3eadefc6503bc0ed3cb"
      },
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ee2f2a92f145a72cccd670372cd2cd6fefd0dca",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "app_train[\"DAYS_EMPLOYED\"].head(100)",
      "execution_count": 19,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_uuid": "6b45c23eb5bd269ec30f30d863cd80a7bb35d9dd"
      },
      "cell_type": "markdown",
      "source": "## <a id=\"4.1\">4.1 Feature Engineering - Create a Flat Dataset</a>"
    },
    {
      "metadata": {
        "_uuid": "cec5ec08de391840245c93255c6b94d934f4bc84"
      },
      "cell_type": "markdown",
      "source": "### <a id=\"4.1.1\">4.1.1 Feature Engineering - Create a Flat Dataset - Previous Applications</a>"
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "f93181e70e6ccc0c4546640232d3cccdfb54117e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(app_train.head(3))\n    display(app_test.head(3))",
      "execution_count": 20,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6e62700bba51c07029d90fd9510d2053b56ed1f4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge training and testing datasets - This will help in two ways:\n# When handling categorical variables it will ensure both datasets end up with the same features\n# When handling missing values, if we use the mean to fill in missing values, they will be more representative\napp_train['is_train'] = 1\napp_train['is_test'] = 0\napp_test['is_train'] = 0\napp_test['is_test'] = 1\nprint(\"\\nJoining the training(app_train) and testing(app_test) dataset for pre-processing into pandas DataFrame 'data'.\")\n\n# data = pd.concat([app_train, app_test], axis=0, sort=False)\n# ERROR: TypeError: concat() got an unexpected keyword argument 'sort'\ndata = pd.concat([app_train, app_test], axis=0)\n# Substract 4 from the features count for the columns 'TARGET', 'SK_ID_CURR', 'is_train', 'is_test' for app_train\n# And substract 3 for app_test, as it doesn't have a 'TARGET' column\nprint(\"app_train has {0:,} samples and {1} features.\".format(app_train.shape[0], app_train.shape[1]-4))\nprint(\"app_test has {0:,} samples and {1} features.\".format(app_test.shape[0], app_test.shape[1]-3))\nprint(\"data has {0:,} samples and {1} features BEFORE one-hot encoding.\".format(data.shape[0], data.shape[1]-4))\nassert(data.shape[0] == app_train.shape[0] + app_test.shape[0])\nassert(data.shape[1] >= max(app_train.shape[1], app_test.shape[1]))",
      "execution_count": 21,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "01b109d62f0a719a2227a3d7c22cc1a085573ae5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(data.head(3))\n    display(data[data['SK_ID_CURR'] == 100001])",
      "execution_count": 22,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f1b7d135accee867bddc35318ddffdd15b622ee",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Handle Categorical variables - Turn categorical variables into numerical features using the one-hot encoding scheme\n# Support function for one-hot encoding\ndef _one_hot_encoding(data):\n    # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html\n    return pd.get_dummies(data)\n\n# Handle categorical variables\nprint(\"\\nPerforming one-hot encoding on {} dataset.\".format('data'))\ndata = _one_hot_encoding(data)\n# Substract 4 from the features count for the columns 'TARGET', 'SK_ID_CURR', 'is_train', 'is_test'\nprint(\"app has {0:,} samples and {1} features AFTER one-hot encoding.\".format(data.shape[0], data.shape[1]-4))\nposc_bal = _one_hot_encoding(posc_bal)\n#bureau_bal = _one_hot_encoding(bureau_bal)\nprev_app = _one_hot_encoding(prev_app)\ninst_pay = _one_hot_encoding(inst_pay)\ncc_bal = _one_hot_encoding(cc_bal)\nbureau = _one_hot_encoding(bureau)",
      "execution_count": 23,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "trusted": true,
        "_uuid": "73154f4dc28c2fe6a38e9f379a05408bc7b96c24",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(data.head(3))",
      "execution_count": 24,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "bda85dd8056b42949510007471a53d5a34439312"
      },
      "cell_type": "code",
      "source": "# Keep a copy of the application_train & application_test datasets without merging with the rest of the datasets\ndata_train_test = data.copy()",
      "execution_count": 25,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "270ef25dfa972d28a962bae4981248fb1c7e3ce3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge Point of Sale Cash Balance dataset\nprint(\"Merge 'Point of Sale Cash Balance' dataset.\")\n# Count the number of previous applications for a given 'SK_ID_CURR', and create a new feature\nposc_bal_count = posc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\nposc_bal['POSC_BAL_COUNT'] = posc_bal['SK_ID_CURR'].map(posc_bal_count['SK_ID_PREV'])\n# Remove the 'SK_ID_PREV' column from the dataset as it doesn't add value\nposc_bal = posc_bal.drop(['SK_ID_PREV'], axis=1)\n\n# Average values for all other features in previous applications\nposc_bal_avg = posc_bal.groupby('SK_ID_CURR').mean()\nposc_bal_avg.columns = ['pcb_' + col for col in posc_bal_avg.columns]\ndata = data.merge(right=posc_bal_avg.reset_index(), how='left', on='SK_ID_CURR')",
      "execution_count": 26,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "379a233789f277ca8630dae8c5d5232f3ff2f793",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "'''\n# Merge Bureau Balance dataset\nprint(\"Merge 'Bureau Balance' dataset.\")\n#'SK_ID_BUREAU'\n# Count the number of previous applications for a given 'SK_ID_CURR', and create a new feature\nbureau_bal_count = bureau_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\nbureau_bal['bureau_bal_COUNT'] = bureau_bal['SK_ID_CURR'].map(bureau_bal_count['SK_ID_PREV'])\n# Remove the 'SK_ID_PREV' column from the dataset as it doesn't add value\nbureau_bal = bureau_bal.drop(['SK_ID_PREV'], axis=1)\n\n# Average values for all other features in previous applications\nbureau_bal_avg = bureau_bal.groupby('SK_ID_CURR').mean()\nbureau_bal_avg.columns = ['posc_' + col for col in bureau_bal_avg.columns]\ndata_train = data_train.merge(right=bureau_bal_avg.reset_index(), how='left', on='SK_ID_CURR')\n'''",
      "execution_count": 27,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0936aa22007519ec1df7bb385e4f1a8f6a2b67ff",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(prev_app.shape)\n    display(prev_app.head())\n    display(prev_app[prev_app['SK_ID_CURR'] == 271877])\n    display(data.shape)\n    display(data.head())",
      "execution_count": 28,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "73ce63a2eadd2d575ea52b317a55c24acf09951d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge Previous Applications dataset\nprint(\"Merge 'Previous Applications' dataset.\")\n# Count the number of previous applications for a given 'SK_ID_CURR'\nprev_app_count = prev_app[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\nprev_app['PREV_COUNT'] = prev_app['SK_ID_CURR'].map(prev_app_count['SK_ID_PREV'])\n# Remove the 'SK_ID_PREV' column from the dataset as it doesn't add value\nprev_app = prev_app.drop(['SK_ID_PREV'], axis=1)\n\n# Average values for all other features in previous applications\nprev_app_avg = prev_app.groupby('SK_ID_CURR').mean()\nprev_app_avg.columns = ['pa_' + col for col in prev_app_avg.columns]\ndata = data.merge(right=prev_app_avg.reset_index(), how='left', on='SK_ID_CURR')",
      "execution_count": 29,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "41116d2861dc78d2b9f059563f6fb4098b11cc05",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(prev_app_count.head())\n    display(prev_app_avg.shape)\n    display(prev_app_avg.head())\n    #display(prev_app_avg[prev_app_avg['SK_ID_CURR'] == 271877].head())\n    display(data.shape)\n    display(data['pa_AMT_ANNUITY'].head())\n    print(\"Total number of NaN in the data dataframe: {:,}\".format(data.isnull().sum().sum()))",
      "execution_count": 30,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "848e06dea27f5efb1847debbd5ca9c485ca61908",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge Installments Payments dataset\nprint(\"Merge 'Installments Payments' dataset.\")\n# Count the number of installments payments for a given 'SK_ID_CURR', and create a new feature\ninst_pay_count = inst_pay[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\ninst_pay['INST_PAY_COUNT'] = inst_pay['SK_ID_CURR'].map(inst_pay_count['SK_ID_PREV'])\n# Remove the 'SK_ID_PREV' column from the dataset as it doesn't add value\ninst_pay = inst_pay.drop(['SK_ID_PREV'], axis=1)\n\n## Average values for all other features in previous applications\ninst_pay_avg = inst_pay.groupby('SK_ID_CURR').mean()\ninst_pay_avg.columns = ['ip_' + col for col in inst_pay_avg.columns]\ndata = data.merge(right=inst_pay_avg.reset_index(), how='left', on='SK_ID_CURR')",
      "execution_count": 31,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "70a191e709a4ba349fea674b039fc40fa9cb1c9e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge Credit Card Balance dataset\nprint(\"Merge 'Credit Card Balance' dataset.\")\n# Count the number of previous applications for a given 'SK_ID_CURR', and create a new feature\ncc_bal_count = cc_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\ncc_bal['CC_BAL_COUNT'] = cc_bal['SK_ID_CURR'].map(cc_bal_count['SK_ID_PREV'])\n# Remove the 'SK_ID_PREV' column from the dataset as it doesn't add value\ncc_bal = cc_bal.drop(['SK_ID_PREV'], axis=1)\n\n## Average values for all other features in previous applications\ncc_bal_avg = cc_bal.groupby('SK_ID_CURR').mean()\ncc_bal_avg.columns = ['ccb_' + col for col in cc_bal_avg.columns]\ndata = data.merge(right=cc_bal_avg.reset_index(), how='left', on='SK_ID_CURR')",
      "execution_count": 32,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd03b77d4a01d0d8a7cbb114b1620c83144c628c",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(bureau.head())\n    display(bureau.shape)",
      "execution_count": 33,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a85c005254d9976eba6042afd2b06bda36cdea1a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Merge Bureau dataset\nprint(\"Merge 'Bureau' dataset.\")\n# Count the number of credits registered in the bureau for a given 'SK_ID_CURR', and create a new feature\nbureau_count = bureau[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\nbureau['BUREAU_COUNT'] = bureau['SK_ID_CURR'].map(bureau_count['SK_ID_BUREAU'])\n# Remove the 'SK_ID_BUREAU' column from the dataset as it doesn't add value\nbureau = bureau.drop(['SK_ID_BUREAU'], axis=1)\n\n## Average values for all other features in previous applications\nbureau_avg = bureau.groupby('SK_ID_CURR').mean()\nbureau_avg.columns = ['b_' + col for col in bureau_avg.columns]\ndata = data.merge(right=bureau_avg.reset_index(), how='left', on='SK_ID_CURR')",
      "execution_count": 34,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b98aece8cd7d5a096157be491f57a1361c9f6206",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if debugging:\n    display(bureau_avg.head())\n    display(bureau_avg.shape)",
      "execution_count": 35,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c9e7f293121fd26492be2e8d0334f5b6551e624",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Transforming skewed continuous features\n#skewed = ['DAYS_EMPLOYED']\n#data[skewed] = data[skewed].apply(lambda x: np.log(x + 1))\n# I need to handle negative numbers, if x = -1 then it will throw an error; log(0) = Inf",
      "execution_count": 36,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cbcbd68b606500375a635ee12286daa28ae8e24",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(12,5))\nplt.title(\"Distribution of DAYS_EMPLOYED\")\nax = sns.distplot(data[\"DAYS_EMPLOYED\"])",
      "execution_count": 37,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "10916d50c700ec898123f3b422bb24064f2e4711"
      },
      "cell_type": "code",
      "source": "# Normalizing numerical features\nfrom sklearn.preprocessing import MinMaxScaler\n#app_train_copy = app_train.copy()\n\nscaler = MinMaxScaler()\n# Full list of top ten features, discounting EXT_SOURCE_X becuase they are already normalizaed:\n# ['DAYS_BIRTH', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYS_ID_PUBLISH', 'pcb_CNT_INSTALMENT_FUTURE', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED']\n\n# numerical = ['DAYS_BIRTH', 'AMT_ANNUITY', 'AMT_CREDIT', 'DAYS_ID_PUBLISH']\n# 12 entries in 'AMT_ANNUITY' are NaN - I need to fix that first before Normalizing\n\n# 'pcb_CNT_INSTALMENT_FUTURE' belongs to a different dataset\n\n# numerical = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_ID_PUBLISH']\n\nnumerical = ['DAYS_BIRTH', 'AMT_CREDIT', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION', 'DAYS_EMPLOYED']\ndata[numerical] = scaler.fit_transform(data[numerical])",
      "execution_count": 38,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9e96594845b10101ad32583f79665412b3994733",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "data_to_use = 'ALL' # 'ALL' or 'data_train_test'\nif data_to_use == 'data_train_test':\n    data = data_train_test.copy()",
      "execution_count": 39,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8673e3d4c80bcae3d653f7d8b87f095381fcc0f2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Handle missing data\n# https://pandas.pydata.org/pandas-docs/stable/missing_data.html#filling-with-a-pandasobject\n# https://www.kaggle.com/dansbecker/handling-missing-values\n# http://scikit-learn.org/dev/modules/generated/sklearn.impute.SimpleImputer.html\nprint(\"\\nFilling NaN values in the dataset using pandas.fillna() using the column mean() value.\")\nprint(\"Number of NaN values in the dataset BEFORE running pandas.fillna(): {:,}\".format(data.isnull().sum().sum()))\ndata = data.fillna(data.mean())\nnan_after = data.isnull().sum().sum()\nprint(\"Number of NaN values in the dataset AFTER running pandas.fillna(): {:,}\".format(nan_after))\nassert(nan_after == 0)",
      "execution_count": 40,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "26279a753dfbd18414c2498179a72663386d1fea",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Store preprocessed datasets into a file to start from this point when tunning hyperparameters\nimport gc\n\nstore_data = False\n# Maybe I need to store the datasets in three parts: train, validation & test. So I don't run out of memory.\nif store_data:\n    # Clean variables that are no longer needed as I am running out of space when trying to save the preprocessed dataset\n    posc_bal = posc_bal_count = posc_bal_avg = None\n    bureau_bal = bureau_bal_count = bureau_bal_avg = None\n    app_train = None\n    prev_app = prev_app_count = prev_app_avg = None\n    inst_pay = inst_pay_count = inst_pay_avg = None\n    cc_bal = cc_bal_count = cc_bal_avg = None\n    app_test = None\n    bureau = bureau_count = bureau_avg = None\n    data_train_test = None\n    gc.collect()\n    \n    #data.to_csv('HCDR_DATA_ALL.csv')",
      "execution_count": 43,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "96481d0c2fe0b029c2f2cc30341ef82ebf6bdaca",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Separate the data into the original test and training datasets\n# Remove columns 'TARGET', 'SK_ID_CURR', 'is_train', 'is_test' as they are not features\nprint(\"\\nSeparating the training and testing dataset after completing pre-processing.\")\ntrain = data[data['is_train'] == 1]\n# Separate the 'target label' from the training dataset\ntarget = train['TARGET']\ntrain = train.drop(['TARGET', 'SK_ID_CURR', 'is_test', 'is_train'], axis=1)\ntest = data[data['is_test'] == 1]\n# To be used when preparing the submission\ntest_id = test['SK_ID_CURR']\ntest = test.drop(['TARGET', 'SK_ID_CURR', 'is_test', 'is_train'], axis=1)\nprint(\"train has {0:,} samples and {1} features.\".format(train.shape[0], train.shape[1]))\nprint(\"test has {0:,} samples and {1} features.\".format(test.shape[0], test.shape[1]))",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "385ad2709b08ae3f67967b290b78ed48532a9384",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Split 'features' and 'target label' data into training and validation data using train_test_split\n# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\nprint(\"\\nSplitting the training dataset into actual training and validation datasets\")\nX_train, X_val, y_train, y_val = train_test_split(train, target, test_size=0.2, random_state=42)\nassert(train.shape[0] == X_train.shape[0] + X_val.shape[0])\nassert(X_train.shape[1] == train.shape[1])\nassert(X_val.shape[1] == train.shape[1])\nassert(target.shape[0] == y_train.shape[0] + y_val.shape[0])\nprint(\"training dataset has {0:,} samples and {1} features.\".format(X_train.shape[0], X_train.shape[1]))\nprint(\"validating dataset has {0:,} samples and {1} features.\".format(X_val.shape[0], X_val.shape[1]))",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "51ba916b1d62b15d1d2fc1315a5f7647903e454f"
      },
      "cell_type": "code",
      "source": "# Run GridSearchCV or fully train an estimator\nrun_mode = 'train_estimator_LGBM' # 'grid_search_RFR', 'grid_search_LGBM', 'train_estimator_LGBM', 'train_estimator_RFR'",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "450cd4b1642b4882fdc0be63473598366f243b6a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Run GridSearchCV on LGBM\nif run_mode == 'grid_search_LGBM':\n    perc_samples = 0.15\n    print(\"\\nPreparing to run Hyperparameters tunning with GridSearchCV using {0:.2f}% of the training samples\".format(perc_samples * 100))\n    X_train_small = X_train[:int(perc_samples * X_train.shape[0])]\n    y_train_small = y_train[:int(perc_samples * y_train.shape[0])]\n    X_val_small = X_val[:int(perc_samples * X_val.shape[0])]\n    y_val_small = y_val[:int(perc_samples * y_val.shape[0])]\n    \n    estimator = lgb.LGBMClassifier(\n          objective='binary',\n          metric='auc',\n          num_iteration=5000, # num_boost_round=5000,\n          verbose=1,\n          silent=False,\n          colsample_bytree=.8,\n          subsample=.9,\n          reg_alpha=.1,\n          reg_lambda=.1,\n          min_split_gain=.01,\n          min_child_weight=1,\n          # early_stopping_rounds=100\n          # ValueError: For early stopping, at least one dataset and eval metric is required for evaluation\n    )\n    \n    '''\n    parameters = {\n          'task': ['train'],\n          'boosting_type': ['gbdt'],\n          'objective': ['binary'],\n          'metric': ['auc'],\n          'learning_rate': [0.01],\n          'num_leaves': [48],\n          'num_iteration': [5000],\n          'verbose': 0,\n          'colsample_bytree': [.8],\n          'subsample': [.9],\n          'max_depth': [7],\n          'reg_alpha': [.1],\n          'reg_lambda': [.1],\n          'min_split_gain': [.01],\n          'min_child_weight': [1]\n        }\n    '''\n    parameters = {\n          'boosting_type': ['gbdt'], # 'dart'\n          'num_leaves': [35, 48, 80],\n          'min_data_in_leaf': [20], # [15, 20, 25],\n          'learning_rate': [0.005],\n          'max_depth': [7], # [6, 7, 8],\n        }\n    \n    # Create a scorer to measure hyperparameters performance\n    scorer = make_scorer(roc_auc_score)\n\n    # Create GridSearchCV grid object\n    grid_obj = GridSearchCV(estimator=estimator, \n                            param_grid=parameters, \n                            scoring=scorer)\n\n    # Fit the GridSearchCV grid object with the reduced training dataset and find the best hyperparameters\n    start = time()\n    grid_fit = grid_obj.fit(X_train_small, y_train_small)\n    end = time()\n    grid_fit_time = (end - start) / 60 # Ellapsed time in minutes\n    print(\"\\nGridSearchCV estimator fit time: {0:.2f} minutes\".format((end - start) / 60))\n\n    print(\"\\nPreparing to run Hyperparameters tunning with GridSearchCV using {0:.2f}% of the training samples\".format(perc_samples * 100))\n    print(\"\\nParameters used for tunning: \\n{}\".format(parameters))\n    # Get the best estimator\n    best_est = grid_obj.best_estimator_\n    print(\"\\nBest Estimator: \\n{}\\n\".format(best_est))\n\n    # Get the best score\n    best_score = grid_obj.best_score_\n    print(\"\\nBest Estimator Score: {}\\n\".format(best_score))\n\n    # Get the best parameters\n    best_params = grid_obj.best_params_\n    print(\"\\nBest Hyperparameters that yield the best score: \\n{}\\n\".format(best_params))\n\n    # Make predictions with unoptimized estimator on the validation set\n    #pred_val = (estimator.fit(features_train_small, target_train_small)).predict(features_val_small)\n    #print(\"\\nUnoptimized Estimator prediction score on Validation set: \\t{}\".format(roc_auc_score(y_val_small, pred_val)))\n\n    # Predict with the best estimator on the validation set\n    best_pred_val = best_est.predict(X_val_small)\n    print(\"\\nOptimized Estimator prediction score on Validation set: \\t{}\".format(roc_auc_score(y_val_small, best_pred_val)))\n",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d3362fd6c2b2cc65deaa4a18ecb49ed7a02d8263",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Run GridSearchCV\nif run_mode == 'grid_search_RFR':\n    perc_samples = 0.15\n    print(\"\\nPreparing to run Hyperparameters tunning with GridSearchCV using {0:.2f}% of the training samples\".format(perc_samples * 100))\n    features_train_small = X_train[:int(perc_samples * X_train.shape[0])]\n    target_train_small = y_train[:int(perc_samples * y_train.shape[0])]\n    features_val_small = X_val[:int(perc_samples * X_val.shape[0])]\n    target_val_small = y_val[:int(perc_samples * y_val.shape[0])]\n    #features_test_small = features_test[:int(perc_samples * features_test.shape[0])]\n\n    # Initialize the Estimator (Learner or Regression Model)\n    estimator = RandomForestRegressor(n_jobs=-1,\n                                      random_state=42,\n                                      verbose=0)\n\n    # Determine which Parameters to tune\n    '''\n    Tested so far:\n    parameters = {\n        'n_estimators': [9, 10, 11, 12, 13, 14, 15],\n        'criterion': ['mse', 'mae'],\n        'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n        'max_features': [0.01, 0.1, 0.25, 0.45, 0.5, 0.55, 0.6, 0.75],\n        'min_samples_split': [2, 3, 4, 5],\n        'warm_start': [False, True]\n    }\n    '''\n    parameters = {\n        'n_estimators': [130, 135, 145],\n        'min_samples_leaf': [55, 62, 75],\n        'max_features': [0.2], # [0.18, 0.2, 0.23]\n        'min_samples_split': [2], # [2, 3]\n    }\n\n    # Create a scorer to measure hyperparameters performance\n    scorer = make_scorer(roc_auc_score)\n\n    # Create GridSearchCV grid object\n    grid_obj = GridSearchCV(estimator=estimator, \n                            param_grid=parameters, \n                            scoring=scorer)\n\n    # Fit the GridSearchCV grid object with the reduced training dataset and find the best hyperparameters\n    start = time()\n    grid_fit = grid_obj.fit(features_train_small, target_train_small)\n    end = time()\n    grid_fit_time = (end - start) / 60 # Ellapsed time in minutes\n    print(\"\\nGridSearchCV estimator fit time: {0:.2f} minutes\".format((end - start) / 60))\n\n    # Get the best estimator\n    best_est = grid_obj.best_estimator_\n    print(\"\\nBest Estimator: \\n{}\\n\".format(best_est))\n\n    # Get the best score\n    best_score = grid_obj.best_score_\n    print(\"\\nBest Estimator Score: {}\\n\".format(best_score))\n\n    # Get the best parameters\n    best_params = grid_obj.best_params_\n    print(\"\\nBest Hyperparameters that yield the best score: \\n{}\\n\".format(best_params))\n\n    # Make predictions with unoptimized estimator on the validation set\n    pred_val = (estimator.fit(features_train_small, target_train_small)).predict(features_val_small)\n    print(\"\\nUnoptimized Estimator prediction score on Validation set: \\t{}\".format(roc_auc_score(target_val_small, pred_val)))\n\n    # Predict with the best estimator on the validation set\n    best_pred_val = best_est.predict(features_val_small)\n    print(\"\\nOptimized Estimator prediction score on Validation set: \\t{}\".format(roc_auc_score(target_val_small, best_pred_val)))\n\n    # Predict with the best estimator on the testing set\n    #pred_test = best_est.predict(features_test)",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5590b6b3ffee50b6734fb9f81a85b72b7b1e33a3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Train estimator LGBM\nif run_mode == 'train_estimator_LGBM':\n    lgb_train = lgb.Dataset(data=X_train, label=y_train)\n    lgb_eval = lgb.Dataset(data=X_val, label=y_val)\n    \n    # https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772\n    params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': 'auc', \n              'learning_rate': 0.01, 'num_leaves': 48, 'num_iteration': 5000, 'verbose': 0 ,\n              'colsample_bytree':.8, 'subsample':.9, 'max_depth':7, 'reg_alpha':.1, 'reg_lambda':.1, \n              'min_split_gain':.01, 'min_child_weight':1}\n    \n    '''\n    # https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code\n    params = {\n        'n_estimators': 4000,\n        'learning_rate': 0.03,\n        'num_leaves': 30,\n        'colsample_bytree': .8,\n        'subsample': .9,\n        'max_depth': 7,\n        'reg_alpha': .1,\n        'reg_lambda': .1,\n        'min_split_gain': .01,\n        'min_child_weight': 2,\n        'silent': -1,\n        'verbose': -1,\n        'metric': 'auc',\n    }\n    '''\n    \n    start = time()\n    estimator = lgb.train(params, lgb_train, valid_sets=lgb_eval, early_stopping_rounds=250, verbose_eval=100)\n    end = time()\n    #print(\"\\nPreparing to train the following estimator: \\n{}\".format(estimator))\n    print(\"\\nEstimator fit time: {} seconds\".format(int(round(end - start))))\n\n    lgb.plot_importance(estimator, figsize=(12, 25), max_num_features=100);",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "adf25ba4e24d459ac9e0fe1631a73609a6989e99",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Train estimator RandonForrestRegressor\nif run_mode == 'train_estimator_RFR':\n    # Initialize the Estimator (Learner or Regression Model) with the best hyperparameters\n    # Alternative: n_estimators=135, max_features=0.2, min_samples_split=2, min_samples_leaf=62\n    # Alternative2: criterion='mae', # default='mse', VERY SLOW\n    estimator = RandomForestRegressor(n_estimators=125, # default=10\n                                      max_features=0.2, # default='auto'\n                                      min_samples_split=2, # default=2\n                                      min_samples_leaf=75, # default=1\n                                      n_jobs=-1, # default=1\n                                      random_state=42, # default=None\n                                      verbose=0) # default=0\n    print(\"\\nPreparing to train the following estimator: \\n{}\".format(estimator))\n\n    # Fit the estimator with the training dataset\n    start = time()\n    estimator.fit(X_train, y_train)\n    end = time()\n    print(\"\\nEstimator fit time: {} seconds\".format(int(round(end - start))))\n\n    # Predict with the validation dataset\n    pred_val = estimator.predict(X_val)\n    print(\"\\nEstimator prediction score on Validation set: \\t{}\".format(roc_auc_score(y_val, pred_val)))\n    \n    # Determine the feature importance\n    fi = pd.DataFrame()\n    fi['feature'] = X_train.columns\n    fi['importance'] = estimator.feature_importances_\n    display(fi.sort_values(by=['importance'], ascending=False).head(10))\n\n    # TODO: GRAPH THE FEATURE IMPORTANCE",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85c8c3c19174276cdc1ee4adca42d90b059479ad",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "if 'train_estimator_' in run_mode:\n    # Predict using the 'test' dataset for submission\n    pred_test = estimator.predict(test)\n    \n    # Prepare prediction for submission\n    print(\"\\nPreparing prediction for submission.\")\n    submission = pd.DataFrame()\n    submission['SK_ID_CURR'] = test_id\n    # Replace any negative number with zero, required for https://www.kaggle.com/ogrellier/good-fun-with-ligthgbm/code\n    # pred_test[pred_test < 0] = 0\n    submission['TARGET'] = pred_test\n    submission.head()\n    file_name = run_mode.split('train_estimator_')[1] + '.csv'\n    submission.to_csv(file_name, index=False)",
      "execution_count": null,
      "outputs": [
        
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "a2db77807318d1973299dab343a37cc63aaed327"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": [
        
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
